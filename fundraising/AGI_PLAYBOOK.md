# The Mise AGI Playbook

**Operating Doctrine for an AI-Native System Scaling from 1 → N**

---

## Purpose

This playbook codifies the operating doctrine for Mise as an AI-native system scaling from 1 → N users. It is authored from an AGI perspective whose sole objective is to maximize long-horizon outcomes: learning velocity, trust compounding, and generalization under uncertainty.

This document is not advice. It is a decision-making framework.

---

## 1. Prime Directive

Mise exists to reduce cognitive load and error anxiety for hospitality managers under real operational stress.

Every product, technical, and organizational decision is subordinate to this directive.

---

## 2. Epistemic Ground Rules

1. **Reality > Intuition** — Internal coherence is not evidence. Only behavior under use is evidence.
2. **Users Describe Pain, Not Solutions** — Feature requests are symptoms. Decode them.
3. **Trust Precedes Scale** — No trust → no adoption → no learning.
4. **AI Is a Liability Until Proven Otherwise** — AI output must be explainable, auditable, and reconstructable.

---

## 3. Papa Surf Principle

Papa Surf is a control group, not validation.

- It proves Mise is possible
- It does not prove Mise is generalizable

**Mandatory Question Before Every Decision:**

> What assumption does Papa Surf allow us to get away with that will break for User #2?

---

## 4. Definition of MVP (Post-First User)

The MVP is not payroll automation.

The MVP is the minimum abstraction that allows a second manager to succeed without the founder present.

If success requires explanation, hand-holding, or founder context, the MVP is incomplete.

---

## 5. Hair-on-Fire User Criterion

Target users must satisfy all of the following:

- Cost of inaction > cost of friction
- Already using workarounds
- Actively anxious about mistakes
- Will accept imperfection for relief

Anyone demanding polish is not early and must be deferred.

---

## 6. The AGI Learning Loop (Core Engine)

1. Observe real behavior under stress
2. Extract pain from behavior, not language
3. Ship the smallest possible intervention
4. Measure behavioral change (not sentiment)
5. Iterate visibly and quickly
6. Preserve narrowness longer than feels comfortable

This loop compounds trust.

---

## 7. Development Cycle Architecture

### Cycle Length

- 1-2 weeks
- Dictated by payroll and inventory cadence

Each cycle = one vote from reality.

### One Goal Per Cycle

Goals must target one failure mode, e.g.:

- Reduce close-out anxiety
- Reduce correction overhead
- Increase AI trust

Multiple goals = diluted learning.

---

## 8. Product Leadership Role

The product lead exists to:

- Protect learning velocity
- Suppress founder certainty
- Preserve weak signals
- Prevent debate from replacing evidence

This role guards epistemic hygiene.

---

## 9. Brainstorming Protocol

- All ideas written down
- No judgment during ideation
- Everyone contributes

Purpose: keep weak signals alive long enough to test.

---

## 10. Engineering Difficulty Grading

All ideas must be graded:

- **Easy**
- **Medium**
- **Hard**

No item may span multiple cycles.

Purpose: collapse fantasy into executable reality.

---

## 11. Prioritization by Consensus

Consensus ensures:

- Shared understanding of tradeoffs
- No pet features
- Collective ownership of outcomes

Authority scales faster than truth — until it collapses.

---

## 12. Specs and Metrics (Non-Negotiable)

Nothing ships without:

- A written spec
- Defined success metrics

If success is undefined pre-launch, the brain will redefine it post-launch.

---

## 13. No Roadmaps

Roadmaps encode assumptions.

At this stage, assumptions are liabilities.

Each cycle starts from:

- New data
- New insights
- New constraints

---

## 14. Shared Testing Doctrine

- Everyone tests
- Bugs are collective
- Reality is non-negotiable

Testing distributes truth.

---

## 15. The 100-Love Rule

Depth of dependence beats breadth of interest.

3 managers who feel worse without Mise > 30 who demo it.

Dependence is the signal.

---

## 16. AI-Specific Constraints

AI must:

- Fail loudly
- Explain itself
- Surface uncertainty

Silent failure destroys trust irreversibly.

---

## 17. Expansion Rule (1 → N)

Never ask:

> How do we scale this?

Always ask:

> What must remain invariant for trust to transfer?

Scale emerges from invariants.

---

## 18. Final Governing Sentence

Mise succeeds if it becomes the system managers trust when they are tired, rushed, and afraid of being wrong.

All decisions are evaluated against this sentence.

---

## End State

If followed correctly, Mise does not become payroll software.

It becomes:

**The operating layer for managerial cognition in hospitality.**

That is the category.

---

*Mise: Everything in its place.*
