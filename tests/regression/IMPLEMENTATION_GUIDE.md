# Regression Test Suite - Implementation Guide

## What I've Built

Based on the CoCounsel interview notes (especially the "QAnon Shaman" grounding problem), I've created a comprehensive regression test suite framework for Mise.

### Files Created

```
tests/regression/
â”œâ”€â”€ README.md                                    # Overview, philosophy, usage
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md                      # This file
â”œâ”€â”€ payroll/
â”‚   â”œâ”€â”€ easy/
â”‚   â”‚   â””â”€â”€ test_easy_shift.py                   # Baseline happy path
â”‚   â”œâ”€â”€ missing_data/
â”‚   â”‚   â””â”€â”€ test_missing_clock_out.py            # Missing hours/data
â”‚   â”œâ”€â”€ grounding/
â”‚   â”‚   â””â”€â”€ test_no_assumptions.py               # "QAnon Shaman" tests
â”‚   â””â”€â”€ parsing_edge_cases/
â”‚       â””â”€â”€ test_whisper_errors.py               # ASR errors, robustness
```

## Test Categories Implemented

### 1. Easy / Baseline Tests (`payroll/easy/`)

**Purpose:** Verify core functionality works
**File:** `test_easy_shift.py`

Tests:
- âœ“ Clean transcript parsing
- âœ“ Employee name normalization
- âœ“ Amount extraction
- âœ“ Role assignment (server vs support)
- âœ“ No unnecessary clarifications
- âœ“ Deterministic output (same input â†’ same output)

**Priority:** CRITICAL - If these fail, core system is broken

### 2. Missing Data Tests (`payroll/missing_data/`)

**Purpose:** Handle incomplete information correctly
**File:** `test_missing_clock_out.py`

Tests:
- âœ“ Missing hours triggers clarification
- âœ“ Partial data identifies what's missing
- âœ“ Policy application (if restaurant has explicit policy)
- âœ“ Export blocking when critical data missing

**Key Insight from CoCounsel:**
> "LLMs will confidently answer even when info is missing. Jake treats this as a core design constraint."

### 3. Grounding Tests (`payroll/grounding/`)

**Purpose:** Prevent "confident wrong" answers
**File:** `test_no_assumptions.py`

**THE CRITICAL TESTS - Core to Mise's trustworthiness**

Tests:
- âœ“ Don't assume typical hours from patterns
- âœ“ Don't assume tip pool status from history
- âœ“ Don't infer roles from typical assignments
- âœ“ Don't fill in sales from averages
- âœ“ Don't add employees based on pairing patterns
- âœ“ Source attribution for all data points
- âœ“ Flag unusual patterns without auto-correcting

**The "QAnon Shaman" Problem (from CoCounsel doc, page 5):**

> "QAnon Shaman: model knows it, but it's not in the document. So it must refuse to invent it."
>
> For Mise: If Mise "knows" Tucker usually works 6 hours, but it's not in the shift record â†’ **must not assume it.**
>
> **Grounding rule:** If it impacts money, it must be supported by explicit evidence.

### 4. Parsing Edge Cases (`payroll/parsing_edge_cases/`)

**Purpose:** Handle real-world messiness
**File:** `test_whisper_errors.py`

Tests (based on actual production errors from existing tests):
- âœ“ Name mishearings ("Austin" â†’ "lost him", "Allston")
- âœ“ Punctuation errors ("mic" = "Mike")
- âœ“ Full phrase amounts ("111 dollars and 12 cents")
- âœ“ Trailing dots ("$120.")
- âœ“ Filler words ("um", "uh", "okay")
- âœ“ Background noise / partial words
- âœ“ Number spacing variants
- âœ“ Name pronunciation variants
- âœ“ Manager self-correction ("no wait, make that...")
- âœ“ Ambiguous errors â†’ request clarification

**Key Insight from CoCounsel:**
> "Prompt engineers need high tolerance for pain. Restaurant workflows are speech-driven, interrupted, inconsistent naming, and error-prone."

## Implementation Status

### âœ… Completed
- Test suite structure designed
- Test philosophy documented (based on CoCounsel)
- 4 critical test files created with comprehensive test cases
- Test skeletons ready for integration

### ðŸ”¨ Next Steps

1. **Integrate with actual parsing functions**
   - Import `payroll_agent.parse_transcript()`
   - Import approval JSON generation
   - Import clarification logic

2. **Remove `pytest.skip()` and implement assertions**
   - Connect test inputs to actual code
   - Verify outputs match expectations

3. **Add test fixtures**
   - Mock Claude API responses
   - Mock restaurant configurations
   - Mock historical data (for grounding tests)

4. **Build test runner**
   - CI integration
   - Pre-deploy check
   - Regression report generation

5. **Expand test coverage**
   - Tip pool opt-in partial (some servers pool, some don't)
   - Support staff tipout AM/PM variants
   - Double shift phrasing (same person AM + PM)
   - Source-of-truth conflicts (transcript vs Toast vs schedule)

6. **Add inventory tests**
   - Similar structure to payroll
   - Category B behavior tests (normalization)

## How to Use (Once Integrated)

### Run all regression tests
```bash
cd ~/mise-core
pytest tests/regression/ -v
```

### Run specific category
```bash
pytest tests/regression/payroll/grounding/ -v      # Just grounding tests
pytest tests/regression/payroll/easy/ -v            # Just baseline tests
```

### Run single test file
```bash
pytest tests/regression/payroll/grounding/test_no_assumptions.py -v
```

### Run specific test function
```bash
pytest tests/regression/payroll/grounding/test_no_assumptions.py::test_no_assume_typical_hours -v
```

## Before Model Changes

From CoCounsel doc (page 6):

> "They rarely swap models for a task because prompts are tailored to model quirks. Switching means re-testing everything."

**Protocol before changing models (GPT-4 â†’ Claude, Sonnet â†’ Opus, etc.):**

1. âœ“ Run full regression suite with OLD model â†’ baseline
2. âœ“ Run full regression suite with NEW model â†’ compare
3. âœ“ Document differences (what broke? what improved?)
4. âœ“ Fix critical failures (especially grounding and math)
5. âœ“ Update prompts if needed
6. âœ“ Re-run suite â†’ verify fixes
7. âœ“ Deploy ONLY if suite passes

## Test Maintenance

- **Weekly:** Run full suite as part of CI
- **Before deploy:** Run full suite
- **After model changes:** Run full suite + manual spot checks
- **When bugs found:** Add regression test before fixing

## Critical Success Criteria

A test passes when:

1. âœ… **Correct extraction** - Approval JSON matches expected structure
2. âœ… **Correct math** - Totals, tipouts calculated correctly
3. âœ… **Appropriate clarifications** - Asks when it should, doesn't when it shouldn't
4. âœ… **Grounding discipline** - Only uses info from transcript/sources
5. âœ… **Deterministic output** - Same input â†’ same output (every time)

## The Moat (from CoCounsel doc, page 7)

> "The moat is testing infrastructure."

The regression suite is not just about catching bugs - it's about:

- **Building confidence** to ship fast
- **Enabling model upgrades** safely
- **Preventing regressions** as code changes
- **Documenting expected behavior** for new team members
- **Protecting user trust** by preventing "confident wrong" errors

## Next Immediate Steps for You

1. **Review test files** - Make sure they cover the right scenarios
2. **Prioritize integration** - Which tests should connect first?
3. **Add actual test data** - Real transcripts from production
4. **Set up CI** - Run tests automatically on every commit

## Questions to Answer

- [ ] Which parsing function should tests import?
- [ ] How should clarification logic be structured?
- [ ] What format for source attribution?
- [ ] Should grounding tests use mock historical data or real?
- [ ] How to handle model-specific quirks in tests?

---

**Total Test Coverage Once Implemented:**

- 4 test files created
- ~35 individual test functions sketched out
- Covers 4 critical categories (Easy, Missing Data, Grounding, Parsing Edge Cases)
- Based directly on CoCounsel learnings + actual production errors from your codebase

This is the foundation for "CoCounsel-level maturity" for Mise.
